{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vPyAyPe1UbBp",
        "outputId": "00b05dfd-8b90-4a39-f067-e9bf60642514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_separable_conv.py:104: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully from: /content/ferplus_model_pd_best.h5\n",
            "\n",
            "Model input shape: (None, 48, 48, 1)\n",
            "Model output shape: (None, 8)\n",
            "\n",
            "Loading samples from CSV: /content/fer2013.csv\n",
            "\n",
            "Quantization settings:\n",
            "  - Optimization: [<Optimize.DEFAULT: 'DEFAULT'>]\n",
            "  - Target ops: INT8\n",
            "  - Input type: INT8\n",
            "  - Output type: INT8\n",
            "  - Calibration samples: 100\n",
            "\n",
            "Converting model... (this may take a minute)\n",
            "Saved artifact at '/tmp/tmp21nlb32x'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name='separable_conv2d_20_input')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136107966232720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107966231568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960367632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960368016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960367056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960368208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960367440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960368976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960366672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960366864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960367824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960368592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960368400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960368784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107960367248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959157008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959157776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959158736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959159120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959157200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959157392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136108089965264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959158928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959159888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959159312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959160656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959160464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959156816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959157584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959158544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959160848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959161808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959162576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959160272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959159696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959163728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959163920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959163536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959166800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959167184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959166032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959165840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959171792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959171984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959172560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933747152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933747536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933746384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933745616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107959160080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933745808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933746192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933748304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933748688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933747344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933747920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933747728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933746768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933749072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933749840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933750224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933748112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933746960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933746576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933749264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136107933750608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/tensorflow/lite/python/convert.py:854: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ Conversion successful!\n",
            "Model successfully converted and saved to: /content/converted_model_int8.tflite\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_af5bd697-382d-4210-8d2a-8e7d1e828a94\", \"converted_model_int8.tflite\", 249104)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# https://ai.google.dev/edge/litert/conversion/tensorflow/quantization/post_training_quantization#integer_only\n",
        "# https://github.com/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\n",
        "\n",
        "#GOOGLE COLAB CONVERSION CODE\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "MODEL_PATH = '/content/ferplus_model_pd_best.h5'\n",
        "CSV_PATH = '/content/fer2013.csv'\n",
        "\n",
        "# A custom SeparableConv2D class to handle old arguments for Keras 3 compatibility\n",
        "class CustomSeparableConv2D(tf.keras.layers.SeparableConv2D):\n",
        "    def __init__(self, *args, kernel_initializer=None, kernel_regularizer=None,\n",
        "                 kernel_constraint=None, groups=1, **kwargs):\n",
        "        # Remap old kernel_initializer to depthwise_initializer and pointwise_initializer\n",
        "        if kernel_initializer and 'depthwise_initializer' not in kwargs:\n",
        "            kwargs['depthwise_initializer'] = kernel_initializer\n",
        "        if kernel_initializer and 'pointwise_initializer' not in kwargs:\n",
        "            kwargs['pointwise_initializer'] = kernel_initializer\n",
        "\n",
        "        # Remap old kernel_regularizer to depthwise_regularizer and pointwise_regularizer\n",
        "        if kernel_regularizer and 'depthwise_regularizer' not in kwargs:\n",
        "            # Ensure the regularizer is correctly instantiated for Keras 3\n",
        "            if isinstance(kernel_regularizer, dict) and kernel_regularizer.get('class_name') == 'L2':\n",
        "                # Keras 3's L2 regularizer expects 'l2_regularization_factor'\n",
        "                l2_value = kernel_regularizer.get('config', {}).get('l2')\n",
        "                if l2_value is not None:\n",
        "                    kwargs['depthwise_regularizer'] = tf.keras.regularizers.L2(l2=l2_value)\n",
        "                    kwargs['pointwise_regularizer'] = tf.keras.regularizers.L2(l2=l2_value)\n",
        "                else:\n",
        "                    kwargs['depthwise_regularizer'] = tf.keras.regularizers.get(kernel_regularizer)\n",
        "                    kwargs['pointwise_regularizer'] = tf.keras.regularizers.get(kernel_regularizer)\n",
        "            else:\n",
        "                kwargs['depthwise_regularizer'] = tf.keras.regularizers.get(kernel_regularizer)\n",
        "                kwargs['pointwise_regularizer'] = tf.keras.regularizers.get(kernel_regularizer)\n",
        "\n",
        "\n",
        "        # Remap old kernel_constraint to depthwise_constraint and pointwise_constraint\n",
        "        if kernel_constraint and 'depthwise_constraint' not in kwargs:\n",
        "            kwargs['depthwise_constraint'] = kernel_constraint\n",
        "        if kernel_constraint and 'pointwise_constraint' not in kwargs:\n",
        "            kwargs['pointwise_constraint'] = kernel_constraint\n",
        "\n",
        "        # 'groups' argument is usually 1 for SeparableConv2D, safely ignore if present\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "# A custom SpatialDropout2D class to handle old arguments for Keras 3 compatibility\n",
        "class CustomSpatialDropout2D(tf.keras.layers.SpatialDropout2D):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        # Remove 'trainable' and 'noise_shape' if present, as they are not constructor arguments for SpatialDropout2D in Keras 3\n",
        "        kwargs.pop('trainable', None)\n",
        "        kwargs.pop('noise_shape', None)\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "# Load the Keras model from the .h5 file, setting compile=False to avoid issues with old optimizer/loss configs\n",
        "with tf.keras.utils.custom_object_scope({'SeparableConv2D': CustomSeparableConv2D, 'SpatialDropout2D': CustomSpatialDropout2D}):\n",
        "    saved_model_dir = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
        "\n",
        "print(\"Model loaded successfully from:\", MODEL_PATH)\n",
        "print(\"\\nModel input shape:\", saved_model_dir.input_shape)\n",
        "print(\"Model output shape:\", saved_model_dir.output_shape)\n",
        "\n",
        "\n",
        "# Initialize the TFLite converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(saved_model_dir)\n",
        "\n",
        "# Apply optimizations for quantization and set up INT8 quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # or tf.uint8\n",
        "converter.inference_output_type = tf.int8  # or tf.uint8\n",
        "\n",
        "# Provide the representative dataset for calibration\n",
        "# Load samples from CSV\n",
        "print(f\"\\nLoading samples from CSV: {CSV_PATH}\")\n",
        "# Load FER2013 CSV\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "# Use training data for calibration\n",
        "train_df = df[df['Usage'] == 'Training']\n",
        "\n",
        "# Define num_samples\n",
        "num_samples = 100 # You can adjust this number based on your needs\n",
        "\n",
        "# Sample random rows\n",
        "sample_df = train_df.sample(n=min(num_samples, len(train_df)), random_state=42)\n",
        "\n",
        "calibration_images = [] # final calibration images for representative, initialized as a list\n",
        "\n",
        "# Convert pixel strings to images\n",
        "for pixel_string in sample_df['pixels']:\n",
        "    # Convert space-separated string to numpy array\n",
        "    pixel_array = np.fromstring(pixel_string, dtype=np.uint8, sep=' ')\n",
        "    # Reshape to 48x48 and normalize\n",
        "    image = pixel_array.reshape(48, 48, 1).astype(np.float32) / 255.0\n",
        "    calibration_images.append(image)\n",
        "\n",
        "# Convert list to numpy array after appending all images\n",
        "calibration_images = np.array(calibration_images)\n",
        "\n",
        "# Generator function\n",
        "def representative_dataset_gen():\n",
        "    for i in range(len(calibration_images)):\n",
        "        sample = calibration_images[i:i+1].astype(np.float32)\n",
        "        yield [sample]\n",
        "\n",
        "# Use in converter\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "\n",
        "# Convert the model\n",
        "print(\"\\nQuantization settings:\")\n",
        "print(f\"  - Optimization: {converter.optimizations}\")\n",
        "print(f\"  - Target ops: INT8\")\n",
        "print(f\"  - Input type: INT8\")\n",
        "print(f\"  - Output type: INT8\")\n",
        "print(f\"  - Calibration samples: {len(calibration_images)}\") # Corrected variable name\n",
        "\n",
        "# Convert the model\n",
        "print(\"\\nConverting model... (this may take a minute)\")\n",
        "try:\n",
        "    tflite_quant_model = converter.convert()\n",
        "    print(\"✓ Conversion successful!\")\n",
        "except Exception as e:\n",
        "    print(f\"✗ Conversion failed: {e}\")\n",
        "    raise\n",
        "\n",
        "# Save the TFLite model to a file on the Colab filesystem\n",
        "tflite_model_filename = '/content/converted_model_int8.tflite'\n",
        "with open(tflite_model_filename, 'wb') as f:\n",
        "    f.write(tflite_quant_model)\n",
        "\n",
        "print(\"Model successfully converted and saved to:\", tflite_model_filename)\n",
        "\n",
        "# Download the model to your local machine\n",
        "files.download(tflite_model_filename)\n"
      ]
    }
  ]
}